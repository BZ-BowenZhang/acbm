{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding activity chains to synthetic populations \n",
    "\n",
    "The purpose of this script is to match each individual in the synthetic population to a respondant from the [National Travel Survey (NTS)](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=5340). \n",
    "\n",
    "### Methods\n",
    "\n",
    "We will try two methods\n",
    "\n",
    "1. categorical matching: joining on relevant socio-demographic variables\n",
    "2. statistical matching, as described in [An unconstrained statistical matching algorithm for combining individual and household level geo-specific census and survey data](https://doi.org/10.1016/j.compenvurbsys.2016.11.003). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from acbm.preprocessing import nts_filter_by_year, nts_filter_by_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load in the datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variables\n",
    "region = \"west-yorkshire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the spc data (parquet format)\n",
    "spc = pd.read_parquet('../data/spc_output/' + region + '_people_hh.parquet')\n",
    "spc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary reduction of the dataset for quick analysis\n",
    "spc = spc.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTS\n",
    "\n",
    "The NTS is split up into multiple tables. We will load in the following tables:\n",
    "- individuals\n",
    "- households\n",
    "- trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where datasets are stored\n",
    "path_psu = \"../data/nts/UKDA-5340-tab/tab/psu_eul_2002-2022.tab\"\n",
    "psu = pd.read_csv(path_psu, sep=\"\\t\")\n",
    "\n",
    "path_individuals = \"../data/nts/UKDA-5340-tab/tab/individual_eul_2002-2022.tab\"\n",
    "nts_individuals = pd.read_csv(path_individuals, sep=\"\\t\")\n",
    "\n",
    "path_households = \"../data/nts/UKDA-5340-tab/tab/household_eul_2002-2022.tab\"\n",
    "nts_households = pd.read_csv(path_households, sep=\"\\t\")\n",
    "\n",
    "path_trips = \"../data/nts/UKDA-5340-tab/tab/trip_eul_2002-2022.tab\"\n",
    "nts_trips = pd.read_csv(path_trips, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by year\n",
    "\n",
    "We will filter the NTS data to only include data from specific years. We can choose only 1 year, or multiple years to increase our sample size and the likelihood of a match with the spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019, 2021, 2022]\n",
    "\n",
    "nts_individuals_filtered = nts_filter_by_year(nts_individuals, psu, years)\n",
    "nts_households_filtered = nts_filter_by_year(nts_households, psu, years)\n",
    "nts_trips_filtered = nts_filter_by_year(nts_trips, psu, years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter by geography \n",
    "\n",
    "I will not do this for categorical matching, as it reduces the sample significantly, and leads to more spc households not being matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions = ['Yorkshire and the Humber', 'North West']\n",
    "\n",
    "# nts_individuals_filtered = nts_filter_by_region(nts_individuals_filtered, psu, regions)\n",
    "# nts_households_filtered = nts_filter_by_region(nts_households_filtered, psu, regions)\n",
    "# nts_trips_filtered = nts_filter_by_region(nts_trips_filtered, psu, regions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries of key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "guide to the dictionaries:\n",
    "\n",
    "_nts_hh: from NTS households table\n",
    "_nts_ind: from NTS individuals table\n",
    "_spc: from SPC\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# ---------- NTS\n",
    "\n",
    "# Create a dictionary for the HHIncome2002_B02ID column\n",
    "income_dict_nts_hh = {\n",
    "     '1': '0-25k',\n",
    "     '2': '25k-50k',\n",
    "     '3': '50k+',\n",
    "    '-8': 'NA',\n",
    "    # should be -10, but\n",
    "    # it could be a typo in household_eul_2002-2022_ukda_data_dictionary\n",
    "    '-1': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the HHoldEmploy_B01ID column\n",
    "# (PT: Part time, FT: Full time)\n",
    "employment_dict_nts_hh = {\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "# Create a dictionary for the Ten1_B02ID column\n",
    "tenure_dict_nts_hh = {\n",
    "    '1': 'Owns / buying',\n",
    "    '2': 'Rents',\n",
    "    '3': 'Other (including rent free)',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# ---------- SPC\n",
    "\n",
    "\n",
    "# create a dictionary for the pwkstat column\n",
    "employment_dict_spc = {\n",
    "    '0': 'Not applicable (age < 16)',\n",
    "    '1': 'Employee FT',\n",
    "    '2': 'Employee PT',\n",
    "    '3': 'Employee unspecified',\n",
    "    '4': 'Self-employed',\n",
    "    '5': 'Unemployed',\n",
    "    '6': 'Retired',\n",
    "    '7': 'Homemaker/Maternal leave',\n",
    "    '8': 'Student',\n",
    "    '9': 'Long term sickness/disability',\n",
    "    '10': 'Other'\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dictionary for the tenure column\n",
    "tenure_dict_spc = {\n",
    "    '1': 'Owned: Owned outright',\n",
    "    '2': 'Owned: Owned with a mortgage or loan or shared ownership',\n",
    "    '3': 'Rented or living rent free: Total',\n",
    "    '4': 'Rented: Social rented',\n",
    "    '5': 'Rented: Private rented or living rent free',\n",
    "    '-8': 'NA',\n",
    "    '-9': 'DNA',\n",
    "    '-10': 'DEAD'\n",
    "}\n",
    "\n",
    "\n",
    "# Combine the dictionaries into a dictionary of dictionaries\n",
    "\n",
    "dict_nts = {\n",
    "    'HHIncome2002_B02ID': income_dict_nts_hh,\n",
    "    'HHoldEmploy_B01ID': employment_dict_nts_hh,\n",
    "    'Ten1_B02ID': tenure_dict_nts_hh\n",
    "}\n",
    "\n",
    "dict_spc = {\n",
    "    'pwkstat': employment_dict_spc,\n",
    "    'tenure': tenure_dict_spc\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Decide on matching variables  \n",
    "\n",
    "We need to identify the socio-demographic characteristics that we will match on. The schema for the synthetic population can be found [here](https://github.com/alan-turing-institute/uatk-spc/blob/main/synthpop.proto). \n",
    "\n",
    "Matching between the SPC and the NTS will happen in two steps: \n",
    "\n",
    "1. Match at the household level\n",
    "2. Match individuals within the household\n",
    "\n",
    "### Household level matching \n",
    "\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Household income   | `HHIncome2002_BO2ID` | `salary_yearly` | NA                   | Group by household ID and sum |\n",
    "| Number of adults   | `HHoldNumAdults`        | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Number of children | `HHoldNumChildren`      | `age_years`     | NA                   | Group by household ID and count |\n",
    "| Employment status  | `HHoldEmploy_B01ID`  | `pwkstat`       | NA                   | a) match to NTS categories. b) group by household ID |\n",
    "| Car ownership      | `NumCar`             | `num_cars`      | SPC is capped at 2. We change all entries > 2 to 2 | NA  |\n",
    "\n",
    "Other columns to match in the future\n",
    "| Variable           | Name (NTS)           | Name (SPC)      | Transformation (NTS) | Transformation (SPC) |\n",
    "| ------------------ | -------------------- | --------------- | -------------------- | -------------------- |\n",
    "| Type of tenancy    | `Ten1_B02ID`         | `tenure`        | ?? | ?? |\n",
    "|  Urban-Rural classification of residence | `Settlement2011EW_B04ID`         | NA     | NA            | Spatial join between [layer](https://www.gov.uk/government/collections/rural-urban-classification) and SPC  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Edit SPC columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household Income\n",
    "\n",
    "# --- Get sum of spc.salary_yearly per household\n",
    "spc['salary_yearly_hh'] = (spc\n",
    "                           .groupby('household')['salary_yearly']\n",
    "                           .transform('sum'))\n",
    "\n",
    "# --- Recode column so that it matches the reported NTS values (Use income_dict_nts_hh dictionary for reference)\n",
    "\n",
    "# Define the bins\n",
    "bins = [0, 24999, 49999, np.inf]\n",
    "# Define the labels for the bins\n",
    "labels = [1, 2, 3]\n",
    "\n",
    "spc['salary_yearly_hh_cat'] = (pd.cut(spc['salary_yearly_hh'], bins=bins, labels=labels)\n",
    "                                 .astype('str')\n",
    "                                 .astype('float'))\n",
    "\n",
    "# replace NA values with -8 (to be consistent with NTS)\n",
    "spc['salary_yearly_hh_cat'] = spc['salary_yearly_hh_cat'].fillna(-8)\n",
    "\n",
    "# Convert the column to int\n",
    "spc['salary_yearly_hh_cat'] = spc['salary_yearly_hh_cat'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household Composition (No. of Adults / Children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of adults and children in the household\n",
    "\n",
    "spc = spc.assign(\n",
    "    is_adult = (spc['age_years'] >= 16).astype(int),\n",
    "    num_adults = lambda df: df.groupby('household')['is_adult'].transform('sum'),\n",
    "    is_child = (spc['age_years'] < 16).astype(int),\n",
    "    num_children = lambda df: df.groupby('household')['is_child'].transform('sum')\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment status\n",
    "\n",
    "# check the colums values from our dictionary\n",
    "dict_spc['pwkstat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only use '1' and '2' for the employment status\n",
    "\n",
    "\n",
    "# Function to count the number of occurences of specific values in a column,\n",
    "# and return a new column per value specified\n",
    "def count_values(group, column, values, value_names):\n",
    "    \"\"\"\n",
    "    Count the number of occurrences of specific values in a column, \n",
    "    and return a new column per value specified.\n",
    "\n",
    "    Parameters:\n",
    "    group (DataFrame): The group of data to count values in.\n",
    "    column (str): The name of the column to count values in.\n",
    "    values (list): The values to count.\n",
    "    value_names (list): The names to use for the new columns in the output.\n",
    "\n",
    "    Returns:\n",
    "    Series: A pandas Series where the index is the value_names and \n",
    "            the values are the counts.\n",
    "    \"\"\"\n",
    "    counts = group[column].value_counts()\n",
    "    return pd.Series([counts.get(val, 0) for val in values], index=value_names)\n",
    "\n",
    "# Apply the function to each group\n",
    "counts_df = (spc.groupby('household')\n",
    "                .apply(count_values,\n",
    "                       column='pwkstat',\n",
    "                       values=[1, 2],\n",
    "                       value_names=['pwkstat_FT_hh','pwkstat_PT_hh']))\n",
    "\n",
    "# Check results\n",
    "# counts_df.head(10)\n",
    "counts_df.iloc[460:480, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to match the SPC values to the NTS\n",
    "dict_nts['HHoldEmploy_B01ID']\n",
    "'''\n",
    "{\n",
    "    '1': 'None',\n",
    "    '2': '0 FT, 1 PT',\n",
    "    '3': '1 FT, 0 PT',\n",
    "    '4': '0 FT, 2 PT',\n",
    "    '5': '1 FT, 1 PT',\n",
    "    '6': '2 FT, 0 PT',\n",
    "    '7': '1 FT, 2+ PT',\n",
    "    '8': '2 FT, 1+ PT',\n",
    "    '9': '0 FT, 3+ PT',\n",
    "    '10': '3+ FT, 0 PT',\n",
    "    '11': '3+ FT, 1+ PT',\n",
    "    '-8': 'NA',\n",
    "    '-10': 'DEAD'}\n",
    " '''\n",
    "\n",
    "# 1) Match each row to the NTS\n",
    "\n",
    "# Define the conditions and outputs.\n",
    "# We are using the keys in dict_nts['HHoldEmploy_B01ID'] as reference\n",
    "conditions = [\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] == 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] == 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] == 1) & (counts_df['pwkstat_PT_hh'] >= 2),\n",
    "    (counts_df['pwkstat_FT_hh'] == 2) & (counts_df['pwkstat_PT_hh'] >= 1),\n",
    "    (counts_df['pwkstat_FT_hh'] == 0) & (counts_df['pwkstat_PT_hh'] >= 3),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] == 0),\n",
    "    (counts_df['pwkstat_FT_hh'] >= 3) & (counts_df['pwkstat_PT_hh'] >= 1)\n",
    "]\n",
    "\n",
    "# Define the corresponding outputs based on dict_nts['HHoldEmploy_B01ID]\n",
    "outputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "# Create a new column using np.select\n",
    "counts_df['pwkstat_NTS_match'] = np.select(conditions,\n",
    "                                           outputs,\n",
    "                                           default= -8)\n",
    "\n",
    "\n",
    "\n",
    "# 2) merge back onto the spc\n",
    "spc = spc.merge(counts_df, left_on='household', right_index=True)\n",
    "spc.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Edit NTS columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of cars\n",
    "\n",
    "- `SPC.num_cars` only has values [0, 1, 2]. 2 is for all households with 2 or more cars\n",
    "- `NTS.NumCar` is more detailed. It has the actual value of the number of cars. We will cap this at 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to match the values\n",
    "def match_values(x):\n",
    "    if x > 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Create a new column in NTS\n",
    "nts_households_filtered.loc[:, 'NumCar_SPC_match'] = nts_households_filtered['NumCar'].apply(match_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of tenancy\n",
    "\n",
    "Breakdown between NTS and SPC is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nts['Ten1_B02ID'], dict_spc['tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary showing how we want the final columns to look like\n",
    "tenure_dict_nts_spc = {\n",
    "    1: 'Owned',\n",
    "    2: 'Rented or rent free',\n",
    "    -8: 'NA',\n",
    "    -9: 'DNA',\n",
    "    -10: 'DEAD'\n",
    "}\n",
    "\n",
    "# Matching NTS to tenure_dict_nts_spc\n",
    "\n",
    "# Create a new dictionary for matching\n",
    "matching_dict_nts_tenure = {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 2\n",
    "}\n",
    "\n",
    "matching_dict_spc_tenure = {\n",
    "    1: 1, #'Owned: Owned outright' : 'Owned'\n",
    "    2: 1, #'Owned: Owned with a mortgage or loan or shared ownership', : 'Owned'\n",
    "    3: 2, #'Rented or living rent free: Total', : 'Rented or rent free'\n",
    "    4: 2, #'Rented: Social rented', : 'Rented or rent free'\n",
    "    5: 2, #'Rented: Private rented or living rent free', : 'Rented or rent free'\n",
    "}\n",
    "\n",
    "# Create a new column in nts_households_filtered\n",
    "nts_households_filtered['tenure_nts_for_matching'] = (nts_households_filtered['Ten1_B02ID']\n",
    "                                                    .map(matching_dict_nts_tenure) # map the values to the new dictionary\n",
    "                                                    .fillna(nts_households_filtered['Ten1_B02ID'])) # fill the NaNs with the original values\n",
    "\n",
    "# Create a new column in spc\n",
    "spc['tenure_spc_for_matching'] = (spc['tenure']\n",
    "                                    .map(matching_dict_spc_tenure) # map the values to the new dictionary\n",
    "                                    .fillna(spc['tenure'])) # fill the NaNs with the original values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Matching at Household Level\n",
    "\n",
    "Now that we've prepared all the columns, we can start matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Categorical matching\n",
    "\n",
    "We will match on the following columns:\n",
    "\n",
    "| Matching variable | NTS column | SPC column |\n",
    "| ------------------| ---------- | ---------- |\n",
    "| Household income  | `HHIncome2002_BO2ID` | `salary_yearly_hh_cat` |\n",
    "| Number of adults  | `HHoldNumAdults` | `num_adults` |\n",
    "| Number of children | `HHoldNumChildren` | `num_children` |\n",
    "| Employment status | `HHoldEmploy_B01ID` | `pwkstat_NTS_match` |\n",
    "| Car ownership | `NumCar_SPC_match` | `num_cars` |\n",
    "| Type of tenancy | `tenure_nts_for_matching` | `tenure_spc_for_matching` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "spc_matching = spc[[\n",
    "    'hid',\n",
    "    'salary_yearly_hh_cat', 'num_adults',\n",
    "    'num_children', 'pwkstat_NTS_match',\n",
    "    'num_cars', 'tenure_spc_for_matching']]\n",
    "\n",
    "# edit the df so that we have one row per hid\n",
    "spc_matching = spc_matching.drop_duplicates(subset='hid')\n",
    "\n",
    "spc_matching.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nts_matching = nts_households_filtered[[\n",
    "    'HouseholdID','HHIncome2002_B02ID',\n",
    "    'HHoldNumAdults', 'HHoldNumChildren',\n",
    "    'HHoldEmploy_B01ID', 'NumCar_SPC_match',\n",
    "    'tenure_nts_for_matching']]\n",
    "\n",
    "nts_matching.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the NTS onto the SPC (each column in SPC can be matched to multiple columns in the NTS)\n",
    "spc_nts = spc_matching.merge(nts_matching,\n",
    "                             left_on= ['salary_yearly_hh_cat',\n",
    "                                       'num_adults',\n",
    "                                       'num_children',\n",
    "                                       'pwkstat_NTS_match',\n",
    "                                       'num_cars',\n",
    "                                       'tenure_spc_for_matching'],\n",
    "                             right_on= ['HHIncome2002_B02ID',\n",
    "                                        'HHoldNumAdults',\n",
    "                                        'HHoldNumChildren',\n",
    "                                        'HHoldEmploy_B01ID',\n",
    "                                        'NumCar_SPC_match',\n",
    "                                        'tenure_nts_for_matching'],\n",
    "                             how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many households from the NTS matched onto each SPC household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many rows from nts_matching are matched onto each hid in spc_matching,\n",
    "spc_nts['count'] = spc_nts.groupby('hid')['HouseholdID'].transform('count')\n",
    "\n",
    "# plot a histogram of the counts, and add a line for the mean value\n",
    "\n",
    "\n",
    "spc_nts_hist = spc_nts.drop_duplicates(subset='hid')\n",
    "\n",
    "\n",
    "spc_nts_hist['count'].plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many rows in spc_matching were not matched onto any rows in nts_matching?\n",
    "spc_nts_hist['count'].value_counts()\n",
    "# calculate th percentage of rows in spc_matching that were not matched onto any rows in nts_matching\n",
    "# round the result to 2 decimal places\n",
    "spc_nts_hist['count'].value_counts(normalize=True).round(2)\n",
    "# plot a histogram of the counts, and add a line for the mean value\n",
    "#spc_nts_hist['count'].plot(kind='hist', bins=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in a dictionary, \n",
    "\n",
    "- Key: SPC hid\n",
    "- Value: List of NTS Household IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each hid in spc_matching is joined onto multiple HouseholdID in nts_matching.\n",
    "# Create a dictionary to store the hid to HouseholdID matches\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "hid_to_HouseholdID = {}\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for index, row in spc_nts.iterrows():\n",
    "    # Get the hid and HouseholdID from the row\n",
    "    hid = row['hid']\n",
    "    HouseholdID = row['HouseholdID']\n",
    "\n",
    "    # If the hid is already a key in the dictionary, append the HouseholdID to its list\n",
    "    if hid in hid_to_HouseholdID:\n",
    "        hid_to_HouseholdID[hid].append(HouseholdID)\n",
    "    # If the hid is not a key in the dictionary, add it with a new list that contains the HouseholdID\n",
    "    else:\n",
    "        hid_to_HouseholdID[hid] = [HouseholdID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 10 entries in the dictionary\n",
    "#list(hid_to_HouseholdID.items())[:100]\n",
    "\n",
    "# access all the values for a specific key in the dictionary\n",
    "hid_to_HouseholdID['E02002183_0010']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each key in the dictionary, sample 1 of the values associated with it and store it in a new dictionary\n",
    "\n",
    "'''\n",
    "- iterate over each key-value pair in the hid_to_HouseholdID dictionary.\n",
    "- For each key-value pair, use np.random.choice(value) to randomly select \n",
    "one item from the list of values associated with the current key.\n",
    "- create a new dictionary hid_to_HouseholdID_sample where each key from the \n",
    "original dictionary is associated with one randomly selected value from the \n",
    "original list of values.\n",
    "\n",
    "'''\n",
    "hid_to_HouseholdID_sample = {key: np.random.choice(value) for key, value in hid_to_HouseholdID.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same logic as cell above, but repeat it multiple times and store each result as a separate dictionary in a list\n",
    "hid_to_HouseholdID_sample_list = [{key: np.random.choice(value) for key, value in hid_to_HouseholdID.items()} for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the datatype of hid_to_HouseholdID_sample_list\n",
    "type(hid_to_HouseholdID_sample_list), type(hid_to_HouseholdID_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acbm-7iKwKWLy-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
